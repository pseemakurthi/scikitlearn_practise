{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "These are the models used for transforming the data and are used in preprocessing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.49213,    0.     ,   18.1    , ...,   20.2    ,   83.45   ,\n",
       "          17.64   ],\n",
       "       [   0.0136 ,   75.     ,    4.     , ...,   21.1    ,  396.9    ,\n",
       "          14.8    ],\n",
       "       [   1.38799,    0.     ,    8.14   , ...,   21.     ,  232.6    ,\n",
       "          27.71   ],\n",
       "       ..., \n",
       "       [   0.09164,    0.     ,   10.81   , ...,   19.2    ,  390.91   ,\n",
       "           5.52   ],\n",
       "       [   7.67202,    0.     ,   18.1    , ...,   20.2    ,  393.1    ,\n",
       "          19.92   ],\n",
       "       [   0.15038,    0.     ,   25.65   , ...,   19.1    ,  370.31   ,\n",
       "          25.41   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from the below output we can see that the features aren't uniform in scale; many models expect (especially linear \n",
    "regress) expect the features to be uniform scale'''\n",
    "np.set_printoptions(suppress=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean   :[   3.76080478   11.06200528   11.23129288    0.06596306    0.55608364\n",
      "    6.26675198   68.31926121    3.7800372     9.65699208  410.43271768\n",
      "   18.4823219   357.58564644   12.72171504]\n",
      "Standard deviation   :[   8.84822339   22.72000576    6.85968431    0.24821752    0.11693991\n",
      "    0.71232885   28.43230582    2.05602318    8.74792233  169.7332148\n",
      "    2.18866808   90.21787114    7.28581478]\n"
     ]
    }
   ],
   "source": [
    "print(\"mean   :{}\".format(X_train.mean(axis = 0)))            #this style is more pythonic and easy to learn and get \n",
    "print(\"Standard deviation   :{}\".format(X_train.std(axis = 0))) #rid of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train) #instead of fit we use transform; a few algorithms gives fit_transform options too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessed Mean [-0. -0.  0. -0. -0.  0. -0. -0.  0. -0.  0.  0. -0.] and STD [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Mean is 0 and std is 1\n",
    "print(\"Postprocessed Mean {} and STD {}\".format(X_train_scaled.mean(axis=0), X_train_scaled.std(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
